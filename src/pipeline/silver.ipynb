{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datetime import datetime, timezone\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from pyspark.sql import DataFrame\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.types import StructType, StructField, TimestampType, StringType\n",
    "import logging\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "CATALOG = \"\"\n",
    "VOLUME_CATALOG = \"main\"\n",
    "VOLUME_SCHEMA = \"engenharia_dados\"\n",
    "VOLUME_NAME = \"aviacao_landing\"\n",
    "LANDING_CSV_BASE_PATH = f\"/Volumes/{VOLUME_CATALOG}/{VOLUME_SCHEMA}/{VOLUME_NAME}/aviacao/landing\"\n",
    "BRONZE_SCHEMA = \"aviacao_bronze\"\n",
    "META_SCHEMA = \"aviacao_meta\"\n",
    "ORIGEM_SISTEMA = \"postgres-aviacao\"\n",
    "\n",
    "TABLE_CONFIGS: Dict[str, Dict] = {\n",
    "    \"companhias_aereas\": {\"schema\": \"aviacao\", \"business_key\": [\"id\"]},\n",
    "    \"modelos_avioes\": {\"schema\": \"aviacao\", \"business_key\": [\"id\"]},\n",
    "    \"aeroportos\": {\"schema\": \"aviacao\", \"business_key\": [\"id\"]},\n",
    "    \"aeronaves\": {\"schema\": \"aviacao\", \"business_key\": [\"id\"]},\n",
    "    \"funcionarios\": {\"schema\": \"aviacao\", \"business_key\": [\"id\"]},\n",
    "    \"clientes\": {\"schema\": \"aviacao\", \"business_key\": [\"id\"]},\n",
    "    \"voos\": {\"schema\": \"aviacao\", \"business_key\": [\"id\"]},\n",
    "    \"reservas\": {\"schema\": \"aviacao\", \"business_key\": [\"id\"]},\n",
    "    \"bilhetes\": {\"schema\": \"aviacao\", \"business_key\": [\"id\"]},\n",
    "    \"bagagens\": {\"schema\": \"aviacao\", \"business_key\": [\"id\"]},\n",
    "    \"manutencoes\": {\"schema\": \"aviacao\", \"business_key\": [\"id\"]},\n",
    "    \"tripulacao_voo\": {\"schema\": \"aviacao\", \"business_key\": [\"id\"]},\n",
    "}\n",
    "\n",
    "TABLE_SCHEMAS: Dict[str, StructType] = {}\n",
    "\n",
    "logger = logging.getLogger(\"aviacao_bronze\")\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter(\"%(asctime)s [%(levelname)s] %(name)s - %(message)s\")\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# Funções de criação e verificação de esquemas e tabelas\n",
    "def qname(schema: str, table: str) -> str:\n",
    "    if CATALOG:\n",
    "        return f\"{CATALOG}.{schema}.{table}\"\n",
    "    return f\"{schema}.{table}\"\n",
    "\n",
    "\n",
    "def now_utc():\n",
    "    return datetime.now(timezone.utc)\n",
    "\n",
    "\n",
    "def init_schema(schema_name: str) -> None:\n",
    "    schema_qualified = f\"{CATALOG}.{schema_name}\" if CATALOG else schema_name\n",
    "    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema_qualified}\")\n",
    "\n",
    "def init_watermark_table() -> None:\n",
    "    init_schema(META_SCHEMA)\n",
    "    wm_table = qname(META_SCHEMA, \"silver_bronze_watermark\")\n",
    "    print(f\"[GLOBAL] Garantindo existência da tabela de watermark: {wm_table}\")\n",
    "    \n",
    "    # Criação da tabela se não existir\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {wm_table} (\n",
    "            tabela STRING NOT NULL,\n",
    "            ultima_data_ref TIMESTAMP NOT NULL,\n",
    "            ultima_execucao_ts TIMESTAMP NOT NULL\n",
    "        )\n",
    "        USING DELTA\n",
    "    \"\"\")\n",
    "    \n",
    "    # A verificação para a constraint pk_watermark_incremental\n",
    "    # Caso a constraint já exista, não vamos tentar criá-la novamente.\n",
    "    try:\n",
    "        spark.sql(f\"\"\"\n",
    "            ALTER TABLE {wm_table} ADD CONSTRAINT pk_watermark_incremental PRIMARY KEY (tabela)\n",
    "        \"\"\")\n",
    "    except Exception as e:\n",
    "        print(f\"[INFO] Constraint pk_watermark_incremental já existe em {wm_table}, ignorando criação.\")\n",
    "\n",
    "def ensure_schema_exists(schema_name: str) -> None:\n",
    "    try:\n",
    "        spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema_name}\")\n",
    "        print(f\"[INFO] Schema {schema_name} criado ou já existente.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Erro ao criar o schema {schema_name}: {str(e)}\")\n",
    "\n",
    "\n",
    "def ensure_delta_table_exists(table_name: str) -> None:\n",
    "    # Garantir que o schema exista antes de criar a tabela\n",
    "    ensure_schema_exists(SILVER_SCHEMA)\n",
    "    \n",
    "    silver_table = qname(SILVER_SCHEMA, table_name)\n",
    "    \n",
    "    try:\n",
    "        spark.sql(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {silver_table} (\n",
    "                id BIGINT,\n",
    "                nome STRING,\n",
    "                codigo_iata STRING,\n",
    "                codigo_icao STRING,\n",
    "                pais STRING,\n",
    "                alianca STRING,\n",
    "                ativo BOOLEAN,\n",
    "                vigencia_inicio TIMESTAMP,\n",
    "                vigencia_fim TIMESTAMP,\n",
    "                is_current BOOLEAN,\n",
    "                origem_sistema STRING,\n",
    "                bronze_load_ts TIMESTAMP,\n",
    "                aud_dh_criacao TIMESTAMP,\n",
    "                aud_dh_alteracao TIMESTAMP,\n",
    "                attr_hash STRING\n",
    "            )\n",
    "            USING DELTA\n",
    "        \"\"\")\n",
    "        print(f\"[INFO] Tabela Delta {silver_table} criada ou já existente.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Erro ao criar a tabela Delta {silver_table}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Função para ler dados incrementais da tabela Bronze\n",
    "def read_bronze_incremental(table_name: str, last_processed_ts: str) -> DataFrame:\n",
    "    # Alterando para usar o nome correto da tabela de bronze com o sufixo \"_changelog\"\n",
    "    bronze_table = qname(BRONZE_SCHEMA, f\"{table_name}_changelog\")\n",
    "\n",
    "    # Verifica se a tabela existe\n",
    "    if not spark.catalog.tableExists(bronze_table):\n",
    "        raise ValueError(f\"A tabela {bronze_table} não existe.\")\n",
    "    \n",
    "    # Lê os dados da tabela de Bronze e filtra com o timestamp\n",
    "    df_bronze = spark.table(bronze_table).filter(F.col(\"bronze_load_ts\") > last_processed_ts)\n",
    "    \n",
    "    return df_bronze\n",
    "\n",
    "\n",
    "# Função para processar dimensões usando SCD Tipo 2\n",
    "def process_scd2_dimension(table_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Função para processar dimensões usando SCD Tipo 2.\n",
    "    \"\"\"\n",
    "    print(f\"================ INÍCIO PROCESSAMENTO SCD2 DIMENSÃO: {table_name} ================\")\n",
    "\n",
    "    # Obtendo o timestamp do último processamento\n",
    "    last_processed_ts = get_last_processed_ts(table_name)\n",
    "\n",
    "    # Lendo os dados incrementais da tabela de bronze\n",
    "    df_bronze = read_bronze_incremental(table_name, last_processed_ts)\n",
    "\n",
    "    df_bronze.show(10)\n",
    "    df_bronze.printSchema()\n",
    "    print(f\"================ FIM DA LEITURA DA DF_BRONZE ================\")\n",
    "\n",
    "    # Garantindo que a tabela Delta de destino (Silver) existe\n",
    "    ensure_delta_table_exists(\"dim_companhias_aereas\")\n",
    "\n",
    "    # Definindo a janela para classificação dos registros\n",
    "    w = Window.partitionBy(\"id\").orderBy(F.col(\"data_ref\").desc(), F.col(\"bronze_load_ts\").desc())\n",
    "\n",
    "    # Criando as mudanças para comparação com a tabela Silver\n",
    "    df_changes = (\n",
    "        df_bronze\n",
    "        .withColumn(\"row_number\", F.row_number().over(w))\n",
    "        .filter(F.col(\"row_number\") == 1)\n",
    "        .drop(\"row_number\")\n",
    "    )\n",
    "\n",
    "    # Definindo as colunas para gerar o hash de atributo (para identificar mudanças)\n",
    "    cols_to_hash = [\"nome\", \"codigo_iata\", \"codigo_icao\", \"pais\", \"alianca\", \"ativo\"]\n",
    "    df_changes = df_changes.withColumn(\n",
    "        \"attr_hash\",\n",
    "        F.sha2(F.concat_ws(\"||\", *[F.col(c).cast(\"string\") for c in cols_to_hash]), 256)\n",
    "    )\n",
    "\n",
    "    df_changes.show(10)\n",
    "    print(f\"================ FIM DA LEITURA DA DF_CHANGES ================\")\n",
    "\n",
    "    # Verifique se df_changes está vazio\n",
    "    if df_changes.count() == 0:\n",
    "        print(f\"[INFO] Nenhuma mudança encontrada para {table_name}. A tabela Bronze está sem atualizações.\")\n",
    "    else:\n",
    "        print(f\"[INFO] Encontradas {df_changes.count()} mudanças para {table_name}.\")\n",
    "    \n",
    "    # Carregando a tabela Silver (já existente)\n",
    "    silver_table = qname(SILVER_SCHEMA, \"dim_companhias_aereas\")\n",
    "    df_silver = spark.table(silver_table).filter(F.col(\"is_current\") == True)\n",
    "\n",
    "    # Realizando a junção entre as mudanças e a tabela Silver\n",
    "    df_join = df_changes.alias(\"chg\").join(\n",
    "        df_silver.alias(\"dim\"),\n",
    "        on=[F.col(\"chg.id\") == F.col(\"dim.cia_id\")],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Preparando os dados para mesclar na tabela Silver\n",
    "    df_to_merge = (\n",
    "        df_join\n",
    "        .filter(\n",
    "            (F.col(\"dim.cia_id\").isNull()) |\n",
    "            (F.col(\"dim.attr_hash\") != F.col(\"chg.attr_hash\"))\n",
    "        )\n",
    "        .select(\n",
    "            \"chg.id\",  # Usando 'id' da tabela de mudanças\n",
    "            \"chg.nome\",\n",
    "            \"chg.codigo_iata\",\n",
    "            \"chg.codigo_icao\",\n",
    "            \"chg.pais\",\n",
    "            \"chg.alianca\",\n",
    "            \"chg.ativo\",\n",
    "            \"chg.data_ref\",\n",
    "            \"chg.bronze_load_ts\",\n",
    "            \"chg.origem_sistema\",\n",
    "            \"chg.attr_hash\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df_to_merge.show()\n",
    "\n",
    "    # Realizando o MERGE na tabela Delta Silver\n",
    "    delta_dim = DeltaTable.forName(spark, silver_table)\n",
    "\n",
    "    delta_dim.alias(\"dim\").merge(\n",
    "        df_to_merge.alias(\"chg\"),\n",
    "        \"CAST(dim.cia_id AS BIGINT) = CAST(chg.id AS BIGINT) AND dim.is_current = true\"\n",
    "    ) \\\n",
    "    .whenMatchedUpdate(\n",
    "        condition=\"dim.attr_hash <> chg.attr_hash\",\n",
    "        set={\n",
    "            \"vigencia_fim\": \"chg.data_ref - INTERVAL 1 MICROSECOND\",\n",
    "            \"is_current\": \"false\",\n",
    "            \"aud_dh_alteracao\": \"current_timestamp()\"\n",
    "        }\n",
    "    ) \\\n",
    "    .whenNotMatchedInsert(\n",
    "        values={\n",
    "            \"cia_id\": \"chg.id\",\n",
    "            \"nome\": \"chg.nome\",\n",
    "            \"codigo_iata\": \"chg.codigo_iata\",\n",
    "            \"codigo_icao\": \"chg.codigo_icao\",\n",
    "            \"pais\": \"chg.pais\",\n",
    "            \"alianca\": \"chg.alianca\",\n",
    "            \"ativo\": \"chg.ativo\",\n",
    "            \"vigencia_inicio\": \"chg.data_ref\",\n",
    "            \"vigencia_fim\": \"TIMESTAMP '9999-12-31 23:59:59'\",\n",
    "            \"is_current\": \"true\",\n",
    "            \"origem_sistema\": \"chg.origem_sistema\",\n",
    "            \"bronze_load_ts\": \"chg.bronze_load_ts\",\n",
    "            \"aud_dh_criacao\": \"current_timestamp()\",\n",
    "            \"aud_dh_alteracao\": \"current_timestamp()\",\n",
    "            \"attr_hash\": \"chg.attr_hash\",\n",
    "        }\n",
    "    ) \\\n",
    "    .execute()\n",
    "\n",
    "    spark.sql(\"SELECT * FROM aviacao_silver.dim_companhias_aereas WHERE is_current = TRUE\").show()\n",
    "\n",
    "    print(f\"================ FIM PROCESSAMENTO SCD2 DIMENSÃO: {table_name} ================\")\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    print(\"Iniciando o processamento da camada Silver...\")\n",
    "    init_watermark_table()\n",
    "    process_scd2_dimension(\"companhias_aereas\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "a13c6a8365e4e76d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
