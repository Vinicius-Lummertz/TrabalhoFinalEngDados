{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from vars import TABLE_CONFIGS\n",
    "from commons import (\n",
    "    init_watermark_table,\n",
    "    get_watermark,\n",
    "    update_watermark,\n",
    "    extract_incremental_from_postgres,\n",
    "    write_landing,\n",
    ")\n",
    "\n",
    "\n",
    "def run_landing_for_table(table_name: str) -> None:\n",
    "    if table_name not in TABLE_CONFIGS:\n",
    "        raise ValueError(f\"Tabela '{table_name}' não está configurada.\")\n",
    "    conf = TABLE_CONFIGS[table_name]\n",
    "    last_wm = get_watermark(table_name)\n",
    "    df_src = extract_incremental_from_postgres(table_name, conf, last_wm)\n",
    "    if df_src.rdd.isEmpty():\n",
    "        update_watermark(table_name, last_wm)\n",
    "        return\n",
    "    batch_id = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    write_landing(df_src, table_name, batch_id)\n",
    "    new_max_data_ref = (\n",
    "        df_src.agg(F.max(\"data_ref\").alias(\"max_dr\")).collect()[0][\"max_dr\"]\n",
    "    )\n",
    "    update_watermark(table_name, new_max_data_ref)\n",
    "\n",
    "\n",
    "init_watermark_table()\n",
    "for tbl in TABLE_CONFIGS.keys():\n",
    "    run_landing_for_table(tbl)\n"
   ],
   "id": "6f43383fb69d22f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
